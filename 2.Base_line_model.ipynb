{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupShuffleSplit, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, log_loss, confusion_matrix, roc_curve, auc, make_scorer\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      delta     theta         alpha          beta         gamma      mean  \\\n",
      "0  0.000123  0.000067  1.039174e-05  4.101177e-07  1.740069e-07 -0.000003   \n",
      "1  0.000208  0.000085  9.628139e-07  2.513081e-07  1.123781e-07  0.000125   \n",
      "\n",
      "       variance  skewness  kurtosis  line_length  label subject_id  \n",
      "0  2.089062e-08 -1.763948  2.470575     0.004479      0    sub-001  \n",
      "1  4.599112e-08  0.497322 -1.170764     0.003333      0    sub-001  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33034, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"eeg_training_data_with_subjects.csv\"\n",
    "#data_path = \"/Users/ishabharti/eeg_training_data_with_subjects.csv\"\n",
    "\n",
    "data = pd.read_csv(data_path) \n",
    "print(data.head(2))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"label\", \"subject_id\"]) \n",
    "y = data[\"label\"]\n",
    "groups = data[\"subject_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split to Avoid Data Leakage (Group-Based)\n",
    "group_split = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(group_split.split(X, y, groups))\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/ishabharti/EEG%20Project/mlruns/621305009683197572', creation_time=1737744675460, experiment_id='621305009683197572', last_update_time=1737744675460, lifecycle_stage='active', name='Random Forest EEG Classification (Advanced)', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up MLflow experiment\n",
    "mlflow.set_experiment(\"Random Forest EEG Classification (Advanced)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'random_forest_model.pkl'\n",
      "Cross-Validation F1 Score: 0.8554521401420414\n",
      "Test F1 Score: 0.3968436626664475\n",
      "Test Log Loss: 0.7875727035027699\n",
      "Confusion Matrix:\n",
      "[[4048 1825]\n",
      " [1844 1207]]\n",
      "ROC AUC: 0.5776791982240946\n"
     ]
    }
   ],
   "source": [
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log experiment type\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    # Define hyperparameters for tuning\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100],\n",
    "        \"max_depth\": [None],\n",
    "        \"min_samples_split\": [2],\n",
    "        \"min_samples_leaf\": [1]\n",
    "    }\n",
    "\n",
    "    # Train the Random Forest Model\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=param_grid[\"n_estimators\"][0],\n",
    "        max_depth=param_grid[\"max_depth\"][0],\n",
    "        min_samples_split=param_grid[\"min_samples_split\"][0],\n",
    "        min_samples_leaf=param_grid[\"min_samples_leaf\"][0],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Evaluate model using cross-validation\n",
    "    f1_scorer = make_scorer(f1_score, average=\"binary\")\n",
    "    cv_f1_scores = cross_val_score(rf, X_train, y_train, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "    mean_f1_cv = np.mean(cv_f1_scores)\n",
    "    mlflow.log_metric(\"mean_f1_cv\", mean_f1_cv)\n",
    "\n",
    "    # Fit the model on the training set\n",
    "    rf.fit(X_train, y_train)\n",
    "    joblib.dump(rf, \"random_forest_model.pkl\")\n",
    "    mlflow.log_artifact(\"random_forest_model.pkl\")  # Log model in MLflow\n",
    "    print(\"Model saved as 'random_forest_model.pkl'\")\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Evaluate metrics\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    test_log_loss = log_loss(y_test, y_proba)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"test_f1\", test_f1)\n",
    "    mlflow.log_metric(\"test_log_loss\", test_log_loss)\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random Guess\")\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(\"roc_curve.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"roc_curve.png\")\n",
    "\n",
    "    # Log confusion matrix\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=[\"True Neg\", \"True Pos\"], columns=[\"Pred Neg\", \"Pred Pos\"])\n",
    "    conf_matrix_df.to_csv(\"confusion_matrix.csv\")\n",
    "    mlflow.log_artifact(\"confusion_matrix.csv\")\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Cross-Validation F1 Score: {mean_f1_cv}\")\n",
    "    print(f\"Test F1 Score: {test_f1}\")\n",
    "    print(f\"Test Log Loss: {test_log_loss}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"ROC AUC: {roc_auc}\")\n",
    "\n",
    "# End MLflow run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test single EEG on trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_single_eeg(raw_eeg_data, band_ranges):\n",
    "    \"\"\"\n",
    "    Preprocess a single EEG dataset and extract features.\n",
    "\n",
    "    Parameters:\n",
    "        raw_eeg_data: Raw EEG data object (e.g., mne.io.Raw)\n",
    "        band_ranges: Dictionary of frequency band ranges\n",
    "    \n",
    "    Returns:\n",
    "        feature_array: A numpy array of extracted features\n",
    "    \"\"\"\n",
    "    # Preprocess the EEG data\n",
    "    raw_eeg_data.filter(1., 40., fir_design='firwin')\n",
    "\n",
    "    # Define epochs\n",
    "    events, event_id = mne.events_from_annotations(raw_eeg_data)\n",
    "    tmin, tmax = -0.2, 0.5\n",
    "    epochs = mne.Epochs(raw_eeg_data, events, event_id, tmin=tmin, tmax=tmax, baseline=(None, 0), preload=True)\n",
    "\n",
    "    # Compute PSD for the entire frequency range\n",
    "    psd = epochs.compute_psd(method='multitaper', fmin=0.5, fmax=40)\n",
    "    psd_data = psd.get_data()  # Shape: (n_epochs, n_channels, n_freqs)\n",
    "    freqs = psd.freqs\n",
    "\n",
    "    # Compute features for each frequency band\n",
    "    band_powers = []\n",
    "    for fmin, fmax in band_ranges.values():\n",
    "        band_indices = (freqs >= fmin) & (freqs < fmax)\n",
    "        band_power = psd_data[:, :, band_indices].mean(axis=(1, 2))  # Aggregate across channels and frequencies\n",
    "        band_powers.append(band_power.mean())  # Average over epochs\n",
    "\n",
    "    # Compute additional features\n",
    "    epoch_data = epochs.get_data().mean(axis=1)  # Aggregate across channels\n",
    "    mean_values = epoch_data.mean()\n",
    "    var_values = epoch_data.var()\n",
    "    skew_values = skew(epoch_data, axis=1).mean()\n",
    "    kurtosis_values = kurtosis(epoch_data, axis=1).mean()\n",
    "    line_length = np.sum(np.abs(np.diff(epoch_data, axis=1)), axis=1).mean()\n",
    "\n",
    "    # Combine all features\n",
    "    feature_array = np.array([\n",
    "        *band_powers, mean_values, var_values, skew_values, kurtosis_values, line_length\n",
    "    ])\n",
    "    return feature_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG file found: ./ds003523/sub-001/ses-01/eeg/sub-001_ses-01_task-VisualWorkingMemory_eeg.set\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import os\n",
    "\n",
    "# Define the dataset directory\n",
    "data_dir = \"./ds003523\"\n",
    "\n",
    "# Subject and session information\n",
    "subject = \"sub-001\"\n",
    "session = \"ses-01\"\n",
    "\n",
    "# Construct the path to the EEG file\n",
    "eeg_file_path = os.path.join(\n",
    "    data_dir,\n",
    "    subject,\n",
    "    session,\n",
    "    \"eeg\",\n",
    "    f\"{subject}_{session}_task-VisualWorkingMemory_eeg.set\"\n",
    ")\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(eeg_file_path):\n",
    "    print(f\"EEG file not found: {eeg_file_path}\")\n",
    "else:\n",
    "    print(f\"EEG file found: {eeg_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/ishabharti/EEG Project/ds003523/sub-001/ses-01/eeg/sub-001_ses-01_task-VisualWorkingMemory_eeg.fdt\n",
      "Reading 0 ... 697174  =      0.000 ...  1394.348 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dl/zd_s8q0x20zbxpy0_dzhksbh0000gn/T/ipykernel_2156/1947841769.py:1: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file_path, preload=True)\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_eeglab(eeg_file_path, preload=True)\n",
    "# Plot the raw data (optional)\n",
    "# raw.plot(duration=5, n_channels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['S  1', 'S  2', 'S  3', 'S 50', 'S 51', 'S 52', 'S100', 'S101', 'S200', 'S201', 'boundary']\n",
      "Not setting metadata\n",
      "511 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 511 events and 351 original time points ...\n",
      "1 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.19355231e-04,  1.44500796e-04,  1.04500588e-05,\n",
       "         1.89622193e-06,  5.15565377e-07, -2.47271096e-05,\n",
       "         9.23275691e-08, -9.91062469e-01,  1.81069777e+00,\n",
       "         2.58580155e-03]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the band ranges used during training\n",
    "band_ranges = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (13, 30),\n",
    "    'gamma': (30, 100)\n",
    "}\n",
    "\n",
    "# Preprocess and extract features for the single EEG sample\n",
    "single_features = preprocess_single_eeg(raw, band_ranges)\n",
    "\n",
    "# Reshape to match the input format expected by the model (1 sample, n_features)\n",
    "single_features = single_features.reshape(1, -1)\n",
    "single_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "model_path = \"random_forest_model.pkl\"\n",
    "# Load the trained Random Forest model\n",
    "try:\n",
    "    model = joblib.load(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Model file not found at: {model_path}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0\n",
      "Predicted Probabilities: [0.81 0.19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/tf/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predict the class\n",
    "predicted_class = model.predict(single_features)[0]\n",
    "\n",
    "# Predict the probability of each class\n",
    "predicted_probabilities = model.predict_proba(single_features)[0]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Predicted Probabilities: {predicted_probabilities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(216, activation = 'relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
