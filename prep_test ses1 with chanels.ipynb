{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from mne.time_frequency import psd_array_multitaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset root\n",
    "data_dir = './ds003523'\n",
    "\n",
    "# Initialize lists for features and labels\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# Define frequency bands\n",
    "band_ranges = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (13, 30),\n",
    "    'gamma': (30, 100)\n",
    "}\n",
    "\n",
    "\n",
    "# Load participants.tsv to get the Group labels\n",
    "participants_file = os.path.join(data_dir, 'participants.tsv')\n",
    "participants = pd.read_csv(participants_file, sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_file = os.path.join(data_dir, 'participants.tsv')\n",
    "participants = pd.read_csv(participants_file, sep='\\t')\n",
    "participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants.Group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute additional features\n",
    "def compute_additional_features(epoch_data):\n",
    "    \"\"\"\n",
    "    Computes additional features like:\n",
    "    - Mean, variance, skewness, and kurtosis for time-domain data\n",
    "    - Line length (signal complexity)\n",
    "    \"\"\"\n",
    "    from scipy.stats import skew, kurtosis\n",
    "\n",
    "    # Mean and variance across time points\n",
    "    mean_values = epoch_data.mean(axis=1)\n",
    "    var_values = epoch_data.var(axis=1)\n",
    "\n",
    "    # Skewness and kurtosis across time points\n",
    "    skew_values = skew(epoch_data, axis=1)\n",
    "    kurtosis_values = kurtosis(epoch_data, axis=1)\n",
    "\n",
    "    # Line length (sum of absolute differences between consecutive samples)\n",
    "    line_length = np.sum(np.abs(np.diff(epoch_data, axis=1)), axis=1)\n",
    "\n",
    "    return mean_values, var_values, skew_values, kurtosis_values, line_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.vstack(all_features)  # Features for all subjects and sessions\n",
    "# y = np.hstack(all_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute additional features (mean, variance, skewness, kurtosis, line length)\n",
    "def compute_additional_features(epoch_data):\n",
    "    if len(epoch_data.shape) != 2:\n",
    "        raise ValueError(f\"Expected 2D array for epoch_data, got {epoch_data.shape}\")\n",
    "\n",
    "    mean_values = epoch_data.mean(axis=1)\n",
    "    var_values = epoch_data.var(axis=1)\n",
    "    skew_values = skew(epoch_data, axis=1)\n",
    "    kurtosis_values = kurtosis(epoch_data, axis=1)\n",
    "    line_length = np.sum(np.abs(np.diff(epoch_data, axis=1)), axis=1)\n",
    "\n",
    "    return mean_values, var_values, skew_values, kurtosis_values, line_length\n",
    "\n",
    "# Initialize variables\n",
    "all_features = []\n",
    "all_labels = []\n",
    "all_subjects = []  # To store subject IDs for each epoch\n",
    "band_ranges = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (13, 30),\n",
    "    'gamma': (30, 100)\n",
    "}\n",
    "expected_feature_count = 16  # Total number of features (5 frequency + 5 time-domain)\n",
    "\n",
    "# Loop through each subject\n",
    "    # Loop through each subject\n",
    "for subject in range(0, 10):  # Adjust range as needed\n",
    "    subject_id = f\"sub-{subject:03d}\"  # Format: sub-001, sub-002, etc.\n",
    "    subject_id_lower = subject_id.lower()\n",
    "    \n",
    "    # Condition to skip a specific subject\n",
    "    if subject_id_lower == \"sub-056\":\n",
    "        continue  # Skip this iteration\n",
    "    # Condition to skip a specific subject\n",
    "    if subject_id_lower == \"sub-077\":\n",
    "        continue  # Skip this iteration\n",
    "    # Condition to skip a specific subject\n",
    "    if subject_id_lower == \"sub-079\":\n",
    "        continue  # Skip this iteration\n",
    "\n",
    "    # Your code for processing other subjects\n",
    "    print(f\"Processing {subject_id_lower}\")\n",
    "\n",
    "    # Check if subject exists in participants.tsv\n",
    "    if subject_id_lower not in participants['participant_id'].values:\n",
    "        print(f\"Subject {subject_id} not found in participants.tsv. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Locate the subject directory\n",
    "    subject_dir = os.path.join(data_dir, subject_id)\n",
    "    if not os.path.exists(subject_dir):\n",
    "        print(f\"Subject directory {subject_id} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Find all available sessions for the subject\n",
    "    #sessions = [s for s in os.listdir(subject_dir) if s.startswith('ses-')]\n",
    "    for session in [\"ses-01\"]:\n",
    "        session_path = os.path.join(subject_dir, session, 'eeg')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for session in [\"ses-01\"]:\n",
    "        session_path = os.path.join(subject_dir, session, 'eeg')\n",
    "\n",
    "        # Retrieve session data using DataLad\n",
    "        os.system(f'datalad get {session_path}')\n",
    "\n",
    "        # Check if the .set file exists for this session\n",
    "        eeg_file = os.path.join(session_path, f\"{subject_id}_{session}_task-VisualWorkingMemory_eeg.set\")\n",
    "        if not os.path.exists(eeg_file):\n",
    "            print(f\"Data for {subject_id}, {session} not found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Load the EEG data\n",
    "        raw = mne.io.read_raw_eeglab(eeg_file, preload=True)\n",
    "\n",
    "        # Preprocess the data\n",
    "        raw.filter(0.5, 100., fir_design='firwin')\n",
    "\n",
    "        # Extract events\n",
    "        events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "        # Define epochs\n",
    "        tmin, tmax = -0.2, 0.5\n",
    "        epochs = mne.Epochs(raw, events, event_id, tmin=tmin, tmax=tmax, baseline=(None, 0), preload=True)\n",
    "\n",
    "        # Compute PSD for the entire frequency range\n",
    "        psd = epochs.compute_psd(method='multitaper', fmin=0.5, fmax=100)\n",
    "        psd_data = psd.get_data()  # Shape: (n_epochs, n_channels, n_freqs)\n",
    "        freqs = psd.freqs\n",
    "\n",
    "        # Compute features for each frequency band\n",
    "        band_powers = {}\n",
    "        for band, (fmin, fmax) in band_ranges.items():\n",
    "            band_indices = (freqs >= fmin) & (freqs < fmax)\n",
    "            band_power = psd_data[:, :, band_indices].mean(axis=2)  # Mean PSD within the band\n",
    "            band_powers[band] = band_power.mean(axis=1)  # Aggregate across channels\n",
    "\n",
    "        # Extract time-domain data from epochs\n",
    "        epoch_data = epochs.get_data().mean(axis=1)  # Aggregate across channels (shape: n_epochs, n_times)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Check Available Channels\n",
    "print(\"Available channels:\", epochs.ch_names)\n",
    "\n",
    "# Step 2: Select & Extract Data for Specific Channels\n",
    "channels_to_extract = [\"AFz\", \"FT8\", \"FC2\", \"PO8\", \"O2\", \"PO7\"]\n",
    "\n",
    "# Ensure the selected channels exist in the dataset\n",
    "channel_indices = [epochs.ch_names.index(ch) for ch in channels_to_extract if ch in epochs.ch_names]\n",
    "\n",
    "print(\"Selected channel indices:\", channel_indices)\n",
    "print(\"Selected channel names:\", [epochs.ch_names[i] for i in channel_indices])\n",
    "\n",
    "# Extract waveform data for selected channels\n",
    "waveform_data = epochs.get_data()[:, channel_indices, :]  # Shape: (n_epochs, n_selected_channels, n_times)\n",
    "\n",
    "# Step 3: Compute Features (Mean Over Time)\n",
    "waveform_features = waveform_data.mean(axis=2)  # Shape: (n_epochs, n_selected_channels)\n",
    "\n",
    "# Step 4: Ensure `all_features` Includes Channels\n",
    "if 'all_features' not in locals():  # Check if all_features exists\n",
    "    all_features = np.zeros((waveform_features.shape[0], 0))  # Initialize with correct row count if empty\n",
    "# Initialize all_features if it's empty\n",
    "all_features = np.zeros((waveform_features.shape[0], 0))  # Initialize with correct row count if empty\n",
    "\n",
    "# Check if all_features is 1D and reshape it temporarily\n",
    "if all_features.ndim == 1:\n",
    "    all_features = all_features[:, np.newaxis]  # Make it 2D if it's 1D\n",
    "\n",
    "# Concatenate waveform features\n",
    "all_features = np.hstack((all_features, waveform_features))\n",
    "\n",
    "# Store feature names (optional, for tracking)\n",
    "feature_channel_names = [\"Original_Features\"] + channels_to_extract\n",
    "# Concatenate waveform features\n",
    "all_features = np.hstack((all_features, waveform_features))\n",
    "\n",
    "# Store feature names (optional, for tracking)\n",
    "feature_channel_names = [\"Original_Features\"] + channels_to_extract\n",
    "\n",
    "# Step 5: Final Verification\n",
    "print(\"Final feature shape:\", all_features.shape)\n",
    "print(\"Feature labels:\", feature_channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension mismatch for sub-009, ses-01: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 510 and the array at index 10 has size 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize as empty lists, NOT NumPy arrays\n",
    "all_features = []\n",
    "all_subjects = []\n",
    "all_labels = []\n",
    "\n",
    "for session in [\"ses-01\"]:  # Or for participant in participants if needed\n",
    "    # Compute additional features\n",
    "    mean_values, var_values, skew_values, kurtosis_values, line_length = compute_additional_features(epoch_data)\n",
    "\n",
    "    # Combine all features into a single array\n",
    "    try:\n",
    "        session_features = np.column_stack([\n",
    "            band_powers['delta'], band_powers['theta'], band_powers['alpha'],\n",
    "            band_powers['beta'], band_powers['gamma'], mean_values,\n",
    "            var_values, skew_values, kurtosis_values, line_length,\n",
    "            \"AFz\", \"FT8\", \"FC2\", \"PO8\", \"O2\", \"PO7\"\n",
    "        ])\n",
    "        print(f\"Session features shape for {subject_id}, {session}: {session_features.shape}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Feature dimension mismatch for {subject_id}, {session}: {e}\")\n",
    "        continue  # This will now work as it's inside the loop\n",
    "\n",
    "    # Append subject ID for each epoch\n",
    "    subject_ids = np.repeat(subject_id, session_features.shape[0])\n",
    "\n",
    "    all_features.append(session_features)\n",
    "    all_subjects.append(subject_ids)\n",
    "\n",
    "    # Get the group label for the subject\n",
    "    group_label = participants.loc[participants['participant_id'] == subject_id_lower, 'Group'].values\n",
    "    if len(group_label) == 0 or pd.isna(group_label[0]):\n",
    "        print(f\"No valid group label found for {subject_id}. Skipping.\")\n",
    "        continue  # This will also work here\n",
    "\n",
    "    # Repeat the label for each epoch in the session\n",
    "    all_labels.append(np.repeat(group_label[0], session_features.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 510 and the array at index 11 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m mean_values, var_values, skew_values, kurtosis_values, line_length \u001b[38;5;241m=\u001b[39m compute_additional_features(epoch_data)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Ensure `waveform_features` is included\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m session_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack([\n\u001b[1;32m      6\u001b[0m     waveform_features,  \u001b[38;5;66;03m# EEG waveform-based features (6 channels)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     band_powers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m'\u001b[39m], band_powers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m'\u001b[39m], band_powers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m     band_powers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m], band_powers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m], mean_values,\n\u001b[1;32m      9\u001b[0m     var_values, skew_values, kurtosis_values, line_length,\n\u001b[1;32m     10\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAFz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFT8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFC2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPO8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPO7\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Other computed features\u001b[39;00m\n\u001b[1;32m     11\u001b[0m ])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Check if feature shape is correct\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession features shape for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_features\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.11/site-packages/numpy/lib/shape_base.py:656\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    654\u001b[0m         arr \u001b[38;5;241m=\u001b[39m array(arr, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ndmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    655\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(arr)\n\u001b[0;32m--> 656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrays, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 510 and the array at index 11 has size 1"
     ]
    }
   ],
   "source": [
    "# Compute additional features\n",
    "mean_values, var_values, skew_values, kurtosis_values, line_length = compute_additional_features(epoch_data)\n",
    "\n",
    "# Ensure `waveform_features` is included\n",
    "session_features = np.column_stack([\n",
    "    waveform_features,  # EEG waveform-based features (6 channels)\n",
    "    band_powers['delta'], band_powers['theta'], band_powers['alpha'],\n",
    "    band_powers['beta'], band_powers['gamma'], mean_values,\n",
    "    var_values, skew_values, kurtosis_values, line_length,\n",
    "     \"AFz\", \"FT8\", \"FC2\", \"PO8\", \"O2\", \"PO7\" # Other computed features\n",
    "])\n",
    "\n",
    "# Check if feature shape is correct\n",
    "print(f\"Session features shape for {subject_id}, {session}: {session_features.shape}\")  # Should be (510, 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>line_length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1.039174e-05</td>\n",
       "      <td>4.101177e-07</td>\n",
       "      <td>1.740069e-07</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>2.089062e-08</td>\n",
       "      <td>-1.763948</td>\n",
       "      <td>2.470575</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>9.628139e-07</td>\n",
       "      <td>2.513081e-07</td>\n",
       "      <td>1.123781e-07</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>4.599112e-08</td>\n",
       "      <td>0.497322</td>\n",
       "      <td>-1.170764</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>3.276360e-05</td>\n",
       "      <td>4.333310e-06</td>\n",
       "      <td>3.227772e-07</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1.393151e-07</td>\n",
       "      <td>0.577952</td>\n",
       "      <td>-0.144130</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>1.999117e-06</td>\n",
       "      <td>3.742573e-07</td>\n",
       "      <td>1.669777e-07</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>1.022358e-08</td>\n",
       "      <td>0.009396</td>\n",
       "      <td>-1.516320</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>7.266782e-06</td>\n",
       "      <td>3.089532e-06</td>\n",
       "      <td>2.499983e-07</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>4.820566e-08</td>\n",
       "      <td>-0.132097</td>\n",
       "      <td>-0.538502</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.116148e-05</td>\n",
       "      <td>6.411663e-06</td>\n",
       "      <td>1.339507e-05</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>3.349408e-08</td>\n",
       "      <td>-0.474056</td>\n",
       "      <td>0.315111</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>7.063376e-06</td>\n",
       "      <td>3.822359e-06</td>\n",
       "      <td>1.338066e-05</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>3.793034e-08</td>\n",
       "      <td>0.057487</td>\n",
       "      <td>-0.799786</td>\n",
       "      <td>0.038020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>7.203328e-06</td>\n",
       "      <td>4.143663e-06</td>\n",
       "      <td>1.342848e-05</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.252372e-08</td>\n",
       "      <td>-0.229151</td>\n",
       "      <td>-0.742725</td>\n",
       "      <td>0.038347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>8.710416e-06</td>\n",
       "      <td>4.783456e-06</td>\n",
       "      <td>1.329040e-05</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>3.571327e-08</td>\n",
       "      <td>-0.222827</td>\n",
       "      <td>-0.480546</td>\n",
       "      <td>0.038169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>9.130378e-06</td>\n",
       "      <td>4.099077e-06</td>\n",
       "      <td>1.336219e-05</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>3.306538e-08</td>\n",
       "      <td>-0.167608</td>\n",
       "      <td>-0.830326</td>\n",
       "      <td>0.038332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4580 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         delta     theta         alpha          beta         gamma      mean  \\\n",
       "0     0.000123  0.000067  1.039174e-05  4.101177e-07  1.740069e-07 -0.000003   \n",
       "1     0.000208  0.000085  9.628139e-07  2.513081e-07  1.123781e-07  0.000125   \n",
       "2     0.000917  0.000410  3.276360e-05  4.333310e-06  3.227772e-07  0.000167   \n",
       "3     0.000069  0.000030  1.999117e-06  3.742573e-07  1.669777e-07 -0.000084   \n",
       "4     0.000231  0.000103  7.266782e-06  3.089532e-06  2.499983e-07  0.000274   \n",
       "...        ...       ...           ...           ...           ...       ...   \n",
       "4575  0.000007  0.000009  1.116148e-05  6.411663e-06  1.339507e-05 -0.000019   \n",
       "4576  0.000038  0.000018  7.063376e-06  3.822359e-06  1.338066e-05 -0.000027   \n",
       "4577  0.000010  0.000009  7.203328e-06  4.143663e-06  1.342848e-05  0.000018   \n",
       "4578  0.000017  0.000013  8.710416e-06  4.783456e-06  1.329040e-05 -0.000026   \n",
       "4579  0.000007  0.000010  9.130378e-06  4.099077e-06  1.336219e-05 -0.000002   \n",
       "\n",
       "          variance  skewness  kurtosis  line_length  label  \n",
       "0     2.089062e-08 -1.763948  2.470575     0.004479      0  \n",
       "1     4.599112e-08  0.497322 -1.170764     0.003333      0  \n",
       "2     1.393151e-07  0.577952 -0.144130     0.005464      0  \n",
       "3     1.022358e-08  0.009396 -1.516320     0.003864      0  \n",
       "4     4.820566e-08 -0.132097 -0.538502     0.004247      0  \n",
       "...            ...       ...       ...          ...    ...  \n",
       "4575  3.349408e-08 -0.474056  0.315111     0.038194      1  \n",
       "4576  3.793034e-08  0.057487 -0.799786     0.038020      1  \n",
       "4577  3.252372e-08 -0.229151 -0.742725     0.038347      1  \n",
       "4578  3.571327e-08 -0.222827 -0.480546     0.038169      1  \n",
       "4579  3.306538e-08 -0.167608 -0.830326     0.038332      1  \n",
       "\n",
       "[4580 rows x 11 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
